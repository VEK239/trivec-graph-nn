{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "iQ3Jho4dJOCz"
   },
   "source": [
    "pip install neptune-notebooks"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtHd_FGJs7Yf"
   },
   "source": [
    "После получения новых датасетов запустим тренировку нашей модели. Будем тренировать ее на протяжении 25 эпох при помощи gpu, записывая логи в нептун. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "buXRvAb_I47q",
    "outputId": "ed12b4b6-1160-4b17-fc92-8f6a8d570bef"
   },
   "source": [
    "!python ../run_trivec.py --metrics_separately --epoch 25 --log --gpu --neptune_project vlasova.elizaveta/test"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/vlasova.elizaveta/test/e/TES-9\n",
      "Use device: cuda\n",
      "Train\n",
      "\n",
      "100% 25/25 [09:06<00:00, 21.85s/it]\n",
      "Test\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2u6VVCQtNEK"
   },
   "source": [
    "Теперь протестируем модель отдельно на тех данных, которые она уже видела и на новых для нее. Для этого я написала отдельный скрипт, который по уже натренированной модели проводит процедуру тестирования. Можно видеть, что все три метрики (roc/auc score, average presicion score, average presition at 50) сильно хуже для новых леккартсв, чем для уже известных."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wsZPujaLJhmZ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6b68b3d5-bf56-4539-a06e-7eb54fbed4c6"
   },
   "source": [
    "!python ../test_trivec.py --metrics_separately --model_path=new_data/trivec_saved/TriVec/11_04_2021/24_15_24_06.pt"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "Test\n",
      "Metric auc_roc is 0.9714980530107913 for seen test data\n",
      "Metric auprc is 0.9495577531452466 for seen test data\n",
      "Metric ap50 is 0.9667610921172114 for seen test data\n",
      "===========================\n",
      "Metric auc_roc is 0.3897883618620548 for new test data\n",
      "Metric auprc is 0.44225102479351147 for new test data\n",
      "Metric ap50 is 0.19069889743992313 for new test data\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yshtMBeXsv9l",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Такое поведение связано с тем, что модель основана на тренировке эмбеддингов, то есть представлений вершин и ребер нашего графа. При создании эмбеддингов мы указываем, что размер словаря для вершин равен количеству уникальных элементов во всем нашем датасете, а сам слой заполняется рандомными весами из равномерного распределения. Тем не менее, если при тренировке модели какие-то вершины совсем не задействуются, их эмбединги и не тренируются, то есть остаются случайными. Из-за этого при попытке что-то предсказать на таких вершинах, мы получаем по сути рандомные значения. Это и видно из полученных метрик.\n",
    "\n"
   ]
  }
 ]
}